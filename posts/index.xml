<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 漂浮的思绪</title>
    <link>https://xnhp0320.github.io/posts/</link>
    <description>Recent content in Posts on 漂浮的思绪</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-zh</language>
    <lastBuildDate>Sat, 25 Jul 2020 07:44:00 +0800</lastBuildDate>
    
	<atom:link href="https://xnhp0320.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    
    <item>
      <title>回到霍格沃茨</title>
      <link>https://xnhp0320.github.io/%E5%9B%9E%E5%88%B0%E9%9C%8D%E6%A0%BC%E6%B2%83%E8%8C%A8/</link>
      <pubDate>Sat, 25 Jul 2020 07:44:00 +0800</pubDate>
      
      <guid>https://xnhp0320.github.io/%E5%9B%9E%E5%88%B0%E9%9C%8D%E6%A0%BC%E6%B2%83%E8%8C%A8/</guid>
      <description>傍晚，我来到霍格沃茨，一个我住过两年的地方。阳光已没有中午的强烈，空气中混杂着先前柏油路被烘烤的气味，合着清风，竟让人有种微醺的感觉。老校区的一切还是老样子，四年的光阴，可以让一个人沧海桑田，但对于霍格沃茨，不过是一个时光的玩笑。我来到对角巷书店，一张陌生的脸打破了曾有的熟悉的气氛，我要买一张《预言家日报》，被告知，这报纸早以于去年使用电子版代替纸制版发行了。在书柜前，我看到那本《霍格沃茨，一段校史》，“是校庆纪念版吗？”，“是的，先生”。嗯，这个曾经只能在图书馆阅览室可以看到的校史资料终于出版发行了，我拿起第七卷，胶版纸，很新，已经没有当年在阅览室里翻阅影印本的那种感觉。熟悉的东西终究不在了，一切开始陌生，陌生的书店店员，陌生的报纸，陌生的书，就如同六年前我初次来到这里的时候一样。
对于霍格沃茨，我始终有一种特殊情感。在这里，我度过了生命中的一段黑暗的日子。当初，我由一个工科生毕业，考研失败，一个人孤零零的来到这所大学当一个小小的技术员，做着最简单的网络维护的工作。绝大多数时间里，我都无所事事的闷在图书馆里，或者一个人跑到对角巷书店，和店员闲聊，那时的对角巷老板是一个音乐迷，常常在阴雨天气放上一张忧郁伤感的爵士，在阳光明媚的日子里来一张清新动人的民谣，大多数唱片是我没有听过的，但他们却像我深交以久但从未谋面的朋友。正如同现在，我的手提箱里还有当年老板送我的一张唱片。在那些悠闲的日子里，合着音乐的旋律，体会着因为光阴流逝而产生的一种微妙的感情，成了我生活很大一部分的乐趣。而现在那一切都是如此的遥远。 六年前的我初次来到霍格沃茨，正赶上霍格沃茨历史上一位伟大人物阿不思邓不利多逝世十周年。纪念仪式办得相当简单，即将退休的麦格教授出席了纪念仪式，这也是她第一次出现在我视野中。她是一个保守的当地人，总是和蔼可亲，有时固执可笑，每当遇到一些网络方面问题，她那一脸无奈的表情，常常让我忍俊不禁。但也正是因为这些让人无奈的故障，使我们成为了朋友，从她那里，我得知不少园艺知识，还有很多霍格沃茨的趣事。当然每次话题的中心都离不开她在外地工作的孙子罗恩，还有她退休后养的那只小猫克鲁克山。
当年的霍格沃茨是多么慢的一个校园。仿佛时间的雕刻刀到了这里都变钝了。以至每次和朋友在一起走路，朋友都会埋怨我的速度。尤其是和大个子海格一起远足的时候。当时由于要帮麦格教授弄园艺，我和园丁海格常常会去学校后山上采集某些有意思得植物。</description>
    </item>
    
    
    
    <item>
      <title>返京</title>
      <link>https://xnhp0320.github.io/%E8%BF%94%E4%BA%AC/</link>
      <pubDate>Sun, 19 Apr 2020 17:39:00 +0800</pubDate>
      
      <guid>https://xnhp0320.github.io/%E8%BF%94%E4%BA%AC/</guid>
      <description>前天返京，一路高铁，耗时六个小时。
原以为一路会看看小说什么的，结果发现是睡了一路，另外中途摘口罩吃了午餐，几个面包。
昨天看了一天剧，2019年也是4月的时候，有个英剧叫《公关》，看着挺有趣。女二号确实很漂亮性感，女一号就是很纠结。当时这个剧就出了两集就没有字幕组跟进了，想不到一年后，能看到全本。第二季也出了。号称是最后一季。
2020年的北京时光拉开了序幕。
五月要来了，北京最好的时候要来了。风刮起来，天蓝起来。</description>
    </item>
    
    
    
    <item>
      <title>又下雨了</title>
      <link>https://xnhp0320.github.io/%E5%8F%88%E4%B8%8B%E9%9B%A8%E4%BA%86/</link>
      <pubDate>Fri, 27 Mar 2020 19:14:57 +0800</pubDate>
      
      <guid>https://xnhp0320.github.io/%E5%8F%88%E4%B8%8B%E9%9B%A8%E4%BA%86/</guid>
      <description>去年三月底的一天下午时候，接到一个电话，说，之前的P2P暴雷的公司调查，要我去做一趟笔录。那是一个雨天，感觉风吹在身上还有点冷。我跑到一个打印店，把之前的app截图打印了下，算是作为证据。在局子里，看到几个居民，以为也是为这事做笔录。一个人在那里絮絮叨叨说了半天，我听了半天也不知道他是怎么了。等了好久，终于有人领我到一个小屋子，写了一堆材料。我问说这事儿有眉目了吗，说，还没呢，只是了解下情况。出局子的时候天开始黑。风冷冷的吹，四下都是蓝黑色，好像是制服和天色的混合。我走上立交桥，周围的街道开始亮灯，也没有多少温暖。家离这儿不远，我走着，最后忘了是在哪吃了晚饭。
那天有点冷，北京难得湿冷一回。
今年发现温泉其实到了三月中旬的时候，已经有点热了。温泉这里就是湿冷阴暗，冬天不好过，但是也过得快。大白天点着个灯，不理会窗外天色阴沉，对着电脑干活，沉默的等待一场暴雨。窗外雨淅沥沥的，挑灯夜读到晚上，有一种奇怪的爽。
又一个下雨天，我在想，如此纠结付出气力，如此沉浸在往日的伤感里，是不是其实也是一个能力问题。能力如同力气，旁人看来不可思议的工作量，耗尽心力和构思的东西，可能做的人觉得，就是需要花时间做而已。如果美和生活需要力气重塑，那么毅然决然的离开，重塑自己的生活的人，都是自身命运的高能力者。如果你对生活充满了欲望，不抗拒每一种口味和可能，可能说明你还是个幸福的人。</description>
    </item>
    
    
    
    
    
    <item>
      <title>Probabilities and Packet Classification I</title>
      <link>https://xnhp0320.github.io/probabilities-and-packet-classification-i/</link>
      <pubDate>Sun, 22 Mar 2020 15:24:54 +0800</pubDate>
      
      <guid>https://xnhp0320.github.io/probabilities-and-packet-classification-i/</guid>
      <description>I wrote this blog in English just because I want to feel like I was writing a thesis. But this is not a thesis or a academic paper, it is just an essay.
For years, I have been trying to understand the enssential nature of the packet classification. This is all due to the my research experience on these algorithms at my Ph.D undergraduate. During that period, I have implemented almost all the existing Decision-Tree based agorithms, and had my own obervations and invented my own algorithm.</description>
    </item>
    
    
    
    <item>
      <title>技术</title>
      <link>https://xnhp0320.github.io/%E6%8A%80%E6%9C%AF/</link>
      <pubDate>Sun, 26 May 2019 23:19:40 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E6%8A%80%E6%9C%AF/</guid>
      <description>很久没有写技术类的博客了。实际上从去年年底到现在最近写了不少有&amp;quot;技术含量&amp;quot;的代码：
 subTimer：一种区分流方向的timer设计 RCU：思考了很多用户态的RCU实现，输出了一篇纯文字的博客，同时线下也分享了一次 Lockless Cache Update：如何无锁更新快表的Cache？  今天给subTimer加了点优化。subTimer有个问题就是如果单边timer超时，但是整体timer没有超时，还是不能调用超时函数，这些堆积的timer停留在LRU链表中，明明超时了又不能清掉，其实对run_timer的效率是个问题。今天想了一个办法，将这些单边超时的timer加入到一个INACTIVE的链表中，但又不调用超时函数，判断timer状态的时候，还是属于pending，但是run_timer的时候不会扫描这个链表，提升了效率，改动也不大。
自己感觉还比较优雅。但是吧，现在感觉subTimer这种一个timer分为两个subTimer的设计，现在看还是有点复杂，尤其是timeout函数会被调用两遍，而且给同步造成了负担。这么看，似乎搞复杂了。</description>
    </item>
    
    
    
    <item>
      <title>非线性的世界</title>
      <link>https://xnhp0320.github.io/%E9%9D%9E%E7%BA%BF%E6%80%A7%E7%9A%84%E4%B8%96%E7%95%8C/</link>
      <pubDate>Sat, 18 May 2019 21:19:03 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E9%9D%9E%E7%BA%BF%E6%80%A7%E7%9A%84%E4%B8%96%E7%95%8C/</guid>
      <description>2011年的时候，我刚进科学院读研，当时应该是博一还是研三，刚开始接触到所谓的SDN。我记得很清楚，那个时候大家对SDN这个是有争议的。紧接着，2012年，Google号称内网全面采用了OpenFlow，SDN初创公司Nicira被VMWare以12亿美刀收购，于是Martin Casado成了硅谷30年最牛叉工程师，SDN成为30年里网络的最大一次革新。很快SD Everything，特斯拉出现了，我听到了SD Battery，大数据火了，我第一次在网络的会议上看到了Spark，AI崛起了，深度了，学习了。年初三月份的时候，大家关注的点还在于《都挺好》里的原生家庭伤害，四月，《我们与恶的距离》探讨了网络和新闻暴力，五月，中美开战了。在我年幼的时候，我总觉得，科技的突破好像是数十年如一日的努力，毕其功于一役的死磕才能实现的。现在，可能是我老了，什么时候事件的密集度已经变成了以月为单位了？What&amp;rsquo;s happening in two years？Nobody knows. 现在，已经是一个非线性的世界了。</description>
    </item>
    
    
    
    <item>
      <title>Write Something</title>
      <link>https://xnhp0320.github.io/write-something/</link>
      <pubDate>Mon, 04 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/write-something/</guid>
      <description>我至今还是保留着写作的习惯，大概是觉得文字能有某种疗愈的方式。其实各种疗愈的方式，归根到底都是一点，逃避。逃避，并且在逃避中进行劳动。人这种生物，还是很看重劳动，无论是否有意义。只要进行了劳动，或多或少你能从中获取一点舒展。如跑步，只是迈开腿而已，跑完一身汗，便好像得到了某种释放。如写作，只是敲几个比特到电脑里而已，敲完，又仿佛得到了点升华。我经常看到豆瓣的上的人，文艺的说自己，不断的读书、写字和邂逅。看到这里，好像最重要的不是前面，而是后面的邂逅。邂逅还是带上了点香艳的气氛，加之在读书写作放在了前面，仿佛读书写字就能和邂逅产生某种关联，因而读书写字就成了邂逅的前提条件。归根结底，人还是欲望的动物，读书写字，只不过是一场有仪式感的守株待兔。
快六月了，一年又过了一半，我又开始茫然。这好像是一种必走的一个流程。一年之计在于春，春天总是希望和欲望的混合体。到了夏天，梦境便开始延伸，会回想起很多事情，然后就伴随着失落和彷徨，到了秋天，北京的秋天，我总是没什么印象，大概是因为比较短暂，只是夏天炎热的延续。转瞬到了冬天，冬天总是干燥、寒冷、劳累，也包含了一点宅和温馨的想象。不过说实话，我很讨厌北京的冬天，可能是因为走在去公司的路上，狂风肆意，总是会感到无比的难受。
那接下来呢，又是新的一年。写到这里有点写不动了。那就这样吧。文艺的节律戛然而止，而我们总是要找到一些理由，让自己继续往下走。要么学点新的玩意儿，告慰日复一日搬砖的辛劳。要么就是在寻找一点刺激，这刺激的来源，可能是一个新的综艺，一个新的手艺，或者一个新的女星，新的性幻想对象。</description>
    </item>
    
    
    
    <item>
      <title>流跟踪系统中的并发设计探讨</title>
      <link>https://xnhp0320.github.io/%E6%B5%81%E8%B7%9F%E8%B8%AA%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E8%AE%BE%E8%AE%A1%E6%8E%A2%E8%AE%A8/</link>
      <pubDate>Mon, 04 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E6%B5%81%E8%B7%9F%E8%B8%AA%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E8%AE%BE%E8%AE%A1%E6%8E%A2%E8%AE%A8/</guid>
      <description>流表，或者严谨一点的说，流跟踪（flow tracking）模块在网络中间盒子（各类网关）中广泛存在。从最简单的LB toa模块（其实借用了linux内核的socket系统来维护流状态），LB中的session表(用于维护和释放localip，记录各种流的原始信息），安全组(security group)的实现，到用来做网关设备的快速路径的主要组成部分，都需要一个流跟踪系统实现功能。可以说，在实际网络产品研发中，流跟踪系统具有较为广泛的应用，同时写起来也有很大的相似度，是有可能被标准化，或者被套路化的产物。但是在具体实践中，却很少有文章探讨这类系统的实现，或者说一些常见pattern（套路）。
流跟踪系统的组成 流跟踪，顾名思义就是维护网络中的每条流的状态。简单来说就是一个哈希表（流的检索）加上一个流表项内存池，一个定时器（流的超时）机制，中间再加上流的状态跳转表，就是流跟踪系统的全部了。每个数据包查找会导致对应流状态的变化，流状态变化会更新定时器的超时时间，流跟踪系统维护的流的出生（流创建）到流的死亡（流超时）。
这个东西看起来设计很简单，但是挑战在于：
 流跟踪（流表）系统每个包都要经过，是性能critical的部分。 流表需要多个核同时读写，需要做好并发设计。 定时器一般是一个异步的系统，如果定时器+流表查找并发互相存在，流表的并发设计就开始有点复杂，流表项的安全回收成为一个问题。  因此流跟踪中的并发设计往往会成为一个挑战，本文针对这个问题做一点探讨。本文主要考虑的是多核共享流表的并发设计，per-thread的流表没有并发问题，不在本文考虑之列。
实际上，这个并发设计的核心问题在于：何时能够安全的释放流表表项？如何在保证安全的前提下，性能开销最小？
ipvs的流跟踪系统设计 首先看看内核中经典的ipvs是怎么来设计这个流跟踪系统的。这个基本上也是各个流跟踪系统的设计的主要的照抄对象。这里分析的是内核3.10+（早期2.6.32时代，使用读写锁，后期变化不大）的ipvs（代码部分用的是4.20的）。
ipvs系统中，流表的并发设计，主要利用了RCU+引用计数，简单摘出内核的流表查找部分的代码：
static inline struct ip_vs_conn * __ip_vs_conn_in_get(const struct ip_vs_conn_param *p) { unsigned int hash; struct ip_vs_conn *cp; hash = ip_vs_conn_hashkey_param(p, false); rcu_read_lock(); hlist_for_each_entry_rcu(cp, &amp;amp;ip_vs_conn_tab[hash], c_list) { if (...) { if (!__ip_vs_conn_get(cp)) continue; /* HIT */ rcu_read_unlock(); return cp; } } rcu_read_unlock(); return NULL; } 对于ipvs流表，内核使用了RCU来进行流表项的读写并发设计，但同时又使用了__ip_vs_conn_get函数对流表表项做引用计数，该函数的代码为：
static inline bool __ip_vs_conn_get(struct ip_vs_conn *cp) { return refcount_inc_not_zero(&amp;amp;cp-&amp;gt;refcnt); } 其中refcount_inc_not_zero是一个per cpu引用计数，暂时可以理解为 atomic_inc_not_zero。也就是说，如果引用计数不为0，那么就增加引用计数，如果为0，说明这个流表表项即将被回收，那么就让流表项不再能够被检索到。</description>
    </item>
    
    
    
    <item>
      <title>临时变量</title>
      <link>https://xnhp0320.github.io/%E4%B8%B4%E6%97%B6%E5%8F%98%E9%87%8F/</link>
      <pubDate>Sun, 27 May 2018 14:47:51 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E4%B8%B4%E6%97%B6%E5%8F%98%E9%87%8F/</guid>
      <description>去年分析过一个右值导致变量生存期变长的日志，当时认为是对象生存期变长了，今天发现并不是如此，当时的小程序：
auto transform(std::string &amp;amp;&amp;amp; a) { std::cout &amp;lt;&amp;lt; &amp;amp;a &amp;lt;&amp;lt; std::endl; return std::ref(a); } int main() { auto a = transform(&amp;#34;hahaha&amp;#34;); std::string &amp;amp;r = a.get(); std::cout &amp;lt;&amp;lt; &amp;amp;r &amp;lt;&amp;lt; std::endl; r[0] = &amp;#39;b&amp;#39;; std::cout &amp;lt;&amp;lt; r &amp;lt;&amp;lt; std::endl; } 当时用的是一个临时的string对象hahaa，今天用了个更简单的对象：
#include &amp;lt;iostream&amp;gt;#include &amp;lt;string&amp;gt;#include &amp;lt;functional&amp;gt; struct B { //default ctor  B() { std::cout &amp;lt;&amp;lt; &amp;#34;B default &amp;#34; &amp;lt;&amp;lt;std::endl; } //copy ctor  B(const B&amp;amp;) { std::cout &amp;lt;&amp;lt; &amp;#34;B copy &amp;#34; &amp;lt;&amp;lt;std::endl; } B&amp;amp; operator=(const B&amp;amp;) { std::cout &amp;lt;&amp;lt;&amp;#34;B assign &amp;#34;&amp;lt;&amp;lt; std::endl; return *this; } B(B &amp;amp;&amp;amp;) {puts(&amp;#34;B(B&amp;amp;&amp;amp;)&amp;#34;);} B&amp;amp; operator=(B &amp;amp;&amp;amp;) { std::cout &amp;lt;&amp;lt;&amp;#34;B move &amp;#34; &amp;lt;&amp;lt; std::endl; return *this; } ~B() { puts(&amp;#34;~B()&amp;#34;);} }; auto transform(B &amp;amp;&amp;amp; a) { std::cout &amp;lt;&amp;lt; &amp;amp;a &amp;lt;&amp;lt; std::endl; return std::ref(a); } int main() { auto a = transform(B()); B &amp;amp;r = a.</description>
    </item>
    
    
    
    <item>
      <title>一周工程经验总结0521~0525</title>
      <link>https://xnhp0320.github.io/%E4%B8%80%E5%91%A8%E5%B7%A5%E7%A8%8B%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%930521~0525/</link>
      <pubDate>Mon, 21 May 2018 13:38:25 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E4%B8%80%E5%91%A8%E5%B7%A5%E7%A8%8B%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%930521~0525/</guid>
      <description> vifo和uio驱动在open的时候，会自发的reset pci设备。这个叫FLR，Function Level Reset，这会导致网卡VF进入reset状态，dpdk需要在进入时等待reset完成，否则会出现vf初始化失败。  </description>
    </item>
    
    
    
    <item>
      <title>一周工程经验总结20180514~20190518</title>
      <link>https://xnhp0320.github.io/%E4%B8%80%E5%91%A8%E5%B7%A5%E7%A8%8B%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%9320180514~20190518/</link>
      <pubDate>Fri, 18 May 2018 19:56:41 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E4%B8%80%E5%91%A8%E5%B7%A5%E7%A8%8B%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%9320180514~20190518/</guid>
      <description>改革进入深水区，公司进入技术深水区。 本周有一下一些认识：
 本周对vhost enqueue做了去锁化优化。  vswitch的设计独特的地方在于，需要考量物理网口RSS多队列和虚机网口的多队列之间的关系。一般来说，RSS的队列数和forwarding线程数是一致的，但是后端virtio的队列数却是用户自己可以配置的，另外，RSS用的哈希算法和virtio网口的多队列哈希算法不一定是一致的，vswitch送入virtio0队列的流的反向包可能从virtio1出来，从而有可能被另一个forwarding线程收到。这意味着整体流表可能要加锁。
我们需要从virtio的代码和内核代码中寻找一些规律性的东西，从而达到最终的性能优化。
本周进行的vhost优化，在于多线程收包后，做哈希，并对virito当前enabled的总队列数做求余，送入对应队列，一般来说需要对队列加锁，但是因为dpdk提供了mp的队列，可以使用无锁算法进行。对队列的consume则可以绑定在单一线程上进行。如下图所示：
这实际上将RTC变成了一个SPL，收上来的包，实际上在soft fifo中进行了下一个部分的处理。
因此在soft fifo往vhsot queue上送包的时候，如果送完包，soft fifo中的包还有，则必须不能丢掉这些包，因为这些包有可能是别的线程送过来的。多个线程的冲突点，则在soft fifo的enqueue中，采用无锁算法优化，应该比spinlock要好。
  vswitch本质是一个IO密集型程序，大量包在enqueue/dequeue中进行。因此cache miss有60%之高，如果前期流表的查找更费的cache的话，整个程序的cache miss惨不忍睹。
  vswitch还需要对各个虚机的流量做简单调度，可以基于虚机本身的流量的历史数据进行判断，如果单次轮询所有的虚机dev，可能会导致没有更多的cpu轮询物理口。这是一个之前没有想到的问题。
  应用将数据包送到virito队列，而vswitch怎么将这些队列信息和流量信息结合？如何在内核+vswitch层面极大的benifit应用？这是vswitch设计的一个更深的考虑。类似于intel的ATR技术，将虚机进程的队列+vcpu核+vswitch的soft fifo的完全绑定。这个应该放在流记录中。
  virito是怎么选取队列的？虚机内核是如何use内核栈？RPS?iperf？这需要对系统更深的理解。
  dpdk最小堆分配的内存为128字节，64字节为malloc头，64字节是任何字节数都要对64字节对齐，因此最少64字节。
  </description>
    </item>
    
    
    
    <item>
      <title>一周工程经验总结0507~0511</title>
      <link>https://xnhp0320.github.io/%E4%B8%80%E5%91%A8%E5%B7%A5%E7%A8%8B%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%930507~0511/</link>
      <pubDate>Fri, 11 May 2018 21:04:03 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E4%B8%80%E5%91%A8%E5%B7%A5%E7%A8%8B%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%930507~0511/</guid>
      <description>  wrk在测试并发的时候，并不是如他结果所显示的那样，在1s内打出了几万个并发连接。通常情况下，-c后面接的数字是并发的数量，一般只有几百而已。wrk在测试中，以循环的形式，每次打开-c个连接，发起GET请求后，立马关闭所有socket，统计一秒钟完成的socket数量。
  因此，单个连接完成的速度会制约wrk在1s内完成的全部的连接的数量，因而，网络速度慢或者拥塞，也会限制最终wrk所能导致的并发连接数。这一点并不直观。
  encap类数据包处理程序，最好在收包之后，对数据包的headroom前64字节做一次预取。有DDIO技术，数据包的payload在DMA之后，直接进入CPU缓存。但是ENCAP会在数据包前面加入包头，这导致持续的Cache miss在encap时。
  URCU在做synchronize_rcu时，有一个类似于call batching的技巧: 即把调用时间上比较相近的synchronize_rcu的调用，用一个concurrent stack存起来，始终让栈顶的那个线程等待其他线程进入静默时区，而让其他的线程等待在futex调用上。等待完成后，栈顶线程会通过futex唤醒其他所有的线程让他们均完成各自的synchronize_rcu调用。
  在使用全局变量做多线程之间的一些同步原语时，最好使用URCU中的一套CMM*的宏，可能更科学一些。
  一个好用的http proxy，polipo，在代理git时，有时候会因为内存不足导致无法git clone。此时需要将他的内存使用量调大一点，chunkhighmark=128 * 1024 * 1024。
  </description>
    </item>
    
    
    
    <item>
      <title>一些有用的数据</title>
      <link>https://xnhp0320.github.io/%E4%B8%80%E4%BA%9B%E6%9C%89%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE/</link>
      <pubDate>Sun, 06 May 2018 20:37:01 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E4%B8%80%E4%BA%9B%E6%9C%89%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE/</guid>
      <description>出处
E5 2630
 L2 cache access costs 4.3ns L3 cache access costs 7.9ns cache miss 32 ns atomic Lock 8.23ns spinlock/unock 16.1ns 34~39 cpu cycles (On the same cpu) System call with SELINUX 75.34ns System call without SELINUX 41.85ns  E5 2695
 spin_{lock,unlock}: 13.94ns local_BH_{disable,enable}: 18 cycles(tsc) 7.410 ns local_IRQ_{disable,enable}: 7 cycles(tsc) 2.860 ns local_IRQ_{save,restore}: 37 cycles(tsc) 14.837 ns  </description>
    </item>
    
    
    
    <item>
      <title>Carousel系统</title>
      <link>https://xnhp0320.github.io/carousel%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Sun, 06 May 2018 15:09:25 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/carousel%E7%B3%BB%E7%BB%9F/</guid>
      <description>花了一天慢悠悠的看完了Carousel的论文，经常看着看着就睡着了，还好换了把椅子，能够躺着看，还蛮惬意的。
Carousel，意为旋转木马，是Google的限速系统，主要应对流量分类越来越多，现有限速器实现CPU占用率高提出的一套优化实现方案。其中采用了Timing Wheel作包缓存，单核单队列，实现方法极其简单。
论文首先对比了，Policer、HTB、FQ/Pacing三种限速器。其中最高效的就是policer，这个就是常用的token bucket 限速器，超过bucket就丢弃数据包，这种限速器不需要缓存，最省cpu，但缺点也在于不准，以及对burst不友好。FQ/pacing和HTB限速准，但CPU占用率高。
Carousel具体算法非常简单，基本还是HTB的一个变种：每个限速器维护一个timestamp，每个包经过时，按照限速器的速率给timestamp做一个递增；当一个包经过所有的限速器之后，将他所经过的所有timestamp中最大的作为包的timestamp，该timestamp表示包的发出时间；将数据包按照其timestamp插入到timing wheel中；timimg wheel随时间的进行，每次清掉一个slots下所有数据包发出，每个slots是一个链表，挂着timestamp落在这个slots中的包。
记一些零散的点：
 Google居然会在Production的服务器上做一些实地性能测量 Qdisc全局锁，在忙的服务器，一天，95th百分位开销是1s Google采用了SoftNIC的设计，网卡的特性使用软件硬件混合实现，给上层应用提供一个比较固定的API接口。SoftNIC采用了轮询的设计，在固定的核上进行，类似于一个vswitch。如果嫌弃内核实现的低效：比如iptables，比如限速，可以挪到SoftNIC/vswitch上实现。这是一个用户态和内核态兼顾的思路，值得借鉴。 流控可以给网络栈进行反压。在vswitch中，可以通过延迟数据包发送完成的方式，给上层应用进行反压，但这个可能需要对virtio的实现做一些修改。 可以试试google的网络测试benchmarking，neper  </description>
    </item>
    
    
    
    <item>
      <title>如何用C&#43;&#43;实现Golang中的slice？</title>
      <link>https://xnhp0320.github.io/%E5%A6%82%E4%BD%95%E7%94%A8c-%E5%AE%9E%E7%8E%B0golang%E4%B8%AD%E7%9A%84slice/</link>
      <pubDate>Sat, 09 Dec 2017 20:13:16 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E5%A6%82%E4%BD%95%E7%94%A8c-%E5%AE%9E%E7%8E%B0golang%E4%B8%AD%E7%9A%84slice/</guid>
      <description>#include &amp;lt;memory&amp;gt;#include &amp;lt;vector&amp;gt;#include &amp;lt;cstddef&amp;gt;#include &amp;lt;iostream&amp;gt; namespace fun { template &amp;lt;typename T&amp;gt; class slice { template &amp;lt;typename&amp;gt; friend slice&amp;lt;T&amp;gt; make_slice(std::size_t ); using iter_type = typename std::vector&amp;lt;T&amp;gt;::iterator; public: slice(const slice &amp;amp;s): ptr(s.ptr), begin(s.begin), end(s.end) {} slice(std::size_t cap) { ptr = std::make_shared&amp;lt;std::vector&amp;lt;T&amp;gt;&amp;gt;(cap); ptr-&amp;gt;reserve(cap); begin = ptr-&amp;gt;begin(); end = ptr-&amp;gt;end(); } slice&amp;lt;T&amp;gt; as_slice(std::size_t begin, std::size_t end) { return slice(*this, this-&amp;gt;begin + begin, this-&amp;gt;begin + end); } T&amp;amp; operator[](std::size_t idx) { return *(begin + idx); } slice&amp;lt;T&amp;gt; &amp;amp; operator=(slice&amp;lt;T&amp;gt; &amp;amp;b) { if(this !</description>
    </item>
    
    
    
    <item>
      <title>Golang的一个坑</title>
      <link>https://xnhp0320.github.io/golang%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91/</link>
      <pubDate>Sat, 09 Dec 2017 14:17:15 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/golang%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91/</guid>
      <description>试着输入以下代码：
package main import &amp;quot;fmt&amp;quot; import &amp;quot;sync&amp;quot; func main() { a := make([]int, 5) var wg sync.WaitGroup wg.Add(5) for i, j := range a { go func() { fmt.Println(i, j) wg.Done() }() } wg.Wait() } 你觉得输出是啥？</description>
    </item>
    
    
    
    <item>
      <title>poetic moment</title>
      <link>https://xnhp0320.github.io/poetic-moment/</link>
      <pubDate>Sun, 03 Sep 2017 23:28:37 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/poetic-moment/</guid>
      <description>我怀恋那些日子，在想象中
激动的不能自已，眼泪和沉迷
远去的让人沸腾的意义
为了那些日子，我要歌唱，
五月的蓝天，六月的风
七月的早晨，和八月的白日梦
而现在，让我安静的
躺在这九月的阳光里，
树下分不清落叶和光影，
你没睡醒。</description>
    </item>
    
    
    
    <item>
      <title>SilkRoad，真的可以用400行的p4实现带状态LB吗？</title>
      <link>https://xnhp0320.github.io/silkroad%E7%9C%9F%E7%9A%84%E5%8F%AF%E4%BB%A5%E7%94%A8400%E8%A1%8C%E7%9A%84p4%E5%AE%9E%E7%8E%B0%E5%B8%A6%E7%8A%B6%E6%80%81lb%E5%90%97/</link>
      <pubDate>Sat, 02 Sep 2017 13:58:50 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/silkroad%E7%9C%9F%E7%9A%84%E5%8F%AF%E4%BB%A5%E7%94%A8400%E8%A1%8C%E7%9A%84p4%E5%AE%9E%E7%8E%B0%E5%B8%A6%E7%8A%B6%E6%80%81lb%E5%90%97/</guid>
      <description>SIGCOMM论文第二弹，说说SilkRoad。
进入主题之前，先八卦一下论文作者单位之多样，来自南加州，facebook，barefoot，和耶鲁。而且看到了熟悉Minlan Yu居然单位是耶鲁大学，跳槽？
##歌词大意
这个论文主要是说如何在交换芯片，或者说ASIC中做LB。LB相对于普通的包转发来说，主要的难点在于需要记录session，也就是stateful packet processing。相对于内存来说，ASIC内部SRAM size是非常有限的，因此如何在较小的空间内存储LB需要的大量流记录是个挑战。
##LB模式
国内公司，主要是互联网公司有很多种LB的模式，而国外的似乎都是最基本的DNAT+SNAT模式。下面假设cip为client ip，DIP为RealServer IP，所谓的DNAT+SNAT模式为：
IN方向（客户访问服务器方向，经过LB做DNAT）：(CIP, VIP) -&amp;gt; (CIP, DIP） OUT方向（服务器回包，不经过LB，通过CTK）：（DIP, CIP）-&amp;gt; (VIP, CIP)
每一个VIP对应一个DIP pool，每个DIP对应一个Real server。
##主要挑战
LB需要存储流记录的一个原因是需要保持PCC（per connection consistency)，也就是一条流中的第一个包如果选择去了一台RealServer(RS)，那么该流剩下的包都应该去同一台RealServer。这基本上是LB设计的常识。实际上，如果后端RS数量是固定的，那么也完全不需要流表存储，我们可以使用如下的方式来无状态转发：
Flow -&amp;gt; Hash(Flow) -&amp;gt; 根据Hash值在DIP pool中选择一个DIP，如DIP[hash % #DIP pool]
而麻烦的是，DIP pool经常需要更新。文章花费了大概一页左右的篇幅说明为啥DIP pool需要更新，更新有多频繁。而这个基本也属于常识：比如健康检查这个DIP对应的RS挂了，比如扩容，比如服务升级（对服务器需要重启）等等。
因此文章在ASIC中做LB的主要两个挑战：1）如何存储流记录到有限的片内SRAM上，2）如何在DIP pool更新的时候依旧保持PCC。
##隐含的挑战
语言上，这个论文写的并不是很清晰，感觉像是临近投稿时赶出来的，也有可能涉及商业机密，对具体细节语焉不详。我反复看了几次，才明白要理解这其中的挑战中具体细节，尤其是第二点挑战。这里说说我的理解：
1）对于DIP的选择，流匹配，流失配，都在数据面完成，不涉及控制面。
如上图所示，如果一个数据包没有匹配中流表，ASIC的逻辑是从DIP pool中自觉选取一个DIP，而不是将数据包上送给控制面（交换机的软件），这个数据包可能就此直接转发了，不会被buffer住！
2）而流表插入新流的操作需要在软件层面展开
这是因为交换机一般采用cuckoo hashing的技术，流表的插入需要复杂的计算和多次表项的搬移。关于cuckoo hasing的具体细节，这里就不展开了。
实际上，整个新流的到达过程在ASIC中处理是这样的：
首先，流表失配，数据包直接从VIP Table中获取DIP发送。
然后，数据包会被记录下来，论文宣称利用了交换芯片的mac leanring用到的leanring filter，将数据包的五元组记录下来，去重，batch上送给software，software这才开始处理流记录的插入。也就是说，当软件开始进行流插入时，底层的数据包已经被转发了。
这样实际上带来的一个问题：在软件需要更新DIP pool的同时，数据包依旧按照老的DIP pool在选取DIP，如果此时直接更新DIP pool，会导致前后不一致，同一个流中的数据包被送到不同的DIP。不能保持PCC。因此我们需要在将更新DIP pool的时间内新到的流记录下来（文中将这些新到的流称之为pending connection），在插入流表的时候，如果是更新期间新到的流，就直接按照老的DIP插入流记录，而是更新完成后的流，就按照新的DIP的方式插入流表。
总而言之，新流的插入是在新包转发之后进行的，这是软件LB和ASIC LB上的最大区别。
而这一点，我认为论文没有说清楚！
##解决方案
首先是流记录的压缩，文章的解决方案就是将只记录流哈希的摘要，而不是流记录本身。文章提出的方案是只记录16bit，而不是五元组（IPv4是13B，IPv6是37B）。文章号称能够记录10M条流，而本身hash摘要只有16bit，从信息论上来说，16bit最多只能区分64K条流，这里又隐含了一些信息，不好理解。我的理解是：
 流摘要和流哈希值不是一回事，流记录的地址是流哈希值算出，而流记录本身的摘要可能是另一个哈希值算出，因此如果流冲突，必须是流哈希冲突+流摘要冲突，如果地址信息足够长，是可以编码10M的流记录的。  遗憾的是，我个人感觉，这篇论文对如何存储这个记录的具体做法，实际上是语焉不详。可能需要具体看了他的p4代码之后才知道具体怎么做的。</description>
    </item>
    
    
    
    <item>
      <title>NFP:Enabling Network Function Parallelism in NFV</title>
      <link>https://xnhp0320.github.io/nfpenabling-network-function-parallelism-in-nfv/</link>
      <pubDate>Sun, 27 Aug 2017 13:20:39 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/nfpenabling-network-function-parallelism-in-nfv/</guid>
      <description>较为粗略的读了一下这篇论文。
论文主要分析了服务链中的不同NF之间的依赖关系，并利用依赖关系设计了一套编排系统，能够对NF运行自动并行化，加速服务链整体的处理吞吐。这个想法有点类似于CPU上的指令集并行的思想，如果两个指令之间并不存在任何依赖关系，CPU可以采用多发射的方式并行执行两个指令。
论文对NF之前的依赖关系做了一个总结，分为Order，Priority和Position。Order表示两个NF之间必须序列化排布，Priority表示两个NF对同一个数据包的处理存在分歧，以哪个NF为主，Position则明确表明NF在整个服务链中的位置（last/first）。
依赖性和数学里面偏序、图论中的拓扑排序等等关系密切。使用Order，Priority和Position这几个原语，可以很容易设计出一套算法，编排NF之间的关系，实现最大的并行化。
##主要贡献
对NF之间的依赖性及并行性进行了挖掘，对NFV系统的设计，具有一定的启发意义。
论文作者有良好的系统设计的功底。实际上现代网络系统科研，拼的不是idea，而是设计和实现。
##Limitations
  为了更大的挖掘NF之间的依赖性，论文对NF对数据包的处理做了假设。这一点感觉在实际中很难站得住脚。例如论文图中认为iptables做的NF只对数据包有读操作而无写操作。这种对读写的判断很深刻的影响了NF并行性的挖掘。而这一点成立的前提只能是NFV系统的操作人员对每一个NF的实现了如指掌。NFV最终的商业模式目前不清晰，因此无法对这个前提是否成立做出判断。
  文中为了避免数据包的多次查找，似乎给每个数据包都attach一个metadata，存储很多自定义的字段，这样的设计只适合于所有NF都只在一台物理机上运行的情况。在实验部分，虽然论文宣称：We evaluate NFP based on a testbed with a number of servers，但是实现部分都围绕着单机虚拟化技术进行描述。如何保证数据包出了机器之后还能进入到另一个server同时进行操作，不清楚。
  本文的系统设计十分巧妙。采用container的技术，避开了繁琐的VM I/O的编码和性能开销，采用shared memory的方式，让所有container共享同一个内存，避免了SRIOV, VHOST-USER, VM2VM数据包传递的开销。采用NF RUNTIME的方式，让所有的NF必须link上到NF runtime上，避免了virtio等一系列麻烦的IO interface编码。同时，这些设计也意味着所有的NF必须开源且互相完全可信。
  ##题外话
NFV系统的商业模式并不清晰：是一家公司独立设计所有的NF模块，掌握所有的NF源码，并且拥有自己的NF编排系统，还是重用云的一套系统，各家公司只是出自己的NF镜像，这两条路似乎和使用场景密切相关。目前来看，各种针对NF的调度和编排的研究都有一个假设：单NF的功能足够原子化，这一点靠近第一条路。而如果是各个公司出镜像的方式，显然是功能越全越好。</description>
    </item>
    
    
    
    <item>
      <title>NFV的价值在哪里？</title>
      <link>https://xnhp0320.github.io/nfv%E7%9A%84%E4%BB%B7%E5%80%BC%E5%9C%A8%E5%93%AA%E9%87%8C/</link>
      <pubDate>Sun, 20 Aug 2017 20:47:41 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/nfv%E7%9A%84%E4%BB%B7%E5%80%BC%E5%9C%A8%E5%93%AA%E9%87%8C/</guid>
      <description>之前在科院的时候做了很久的NFV。现在回过头来看，其实根本没懂啥是NFV，或者当时的思考过于局限了。所里做的，其实更多的是一种软件开发，和所谓的“网工”差别很大。这里说下对这玩意的一个阶段性思考。
首先顾名思义，网络功能虚拟化，网络功能其实好理解，无非是网元设备（nat/fw/lb/rate limiter/epc/&amp;hellip;)，当然往大的方向思考，提供connectivity的都叫网络功能，但是那已经是网络虚拟化的概念了，NFV基本还是围绕middlebox的一系列技术。难点在于虚拟化。按照以前的说法，所谓虚拟化就是把网络功能往虚拟机里实现，于是我们就虚拟化了。哇，真的是easy，但是虚拟机转发性能不行啊，一堆人开始吭哧吭哧的优化转发性能，改qemu/kvm，搞vhost-user，SR-IOV，最后发现都不行，那咋办？只能上智能网卡了，搞了一对牛逼哄哄的技术，成功的提高了这个行业的门槛，造就一堆NFV工程师。
但是回过头来想想，NFV不是倡导使用高性能标准化（commodity）的server来实现网元功能嘛，咋到最后你还得用智能网卡这种specific的硬件来解决吞吐问题了呢？那不是有点本末倒置。如果我用DPDK+通用网卡能够大幅提升网络处理的性能，咋上了你的NFV之后，网络性能反而下降了呢？那我还干NFV干嘛，就是为了虚拟化而虚拟化？
NF跑虚拟机的好处是什么？反正我一直没太想明白。Nicira的人在一篇NSDI中讲过一个观点：某些大型企业，其内部的IT系统就是围绕着一些专用的网元设备构建的，迁移到云上去之后，他的系统还得为云的API重新打造，费时费力，如果这个时候能够直接把某些虚拟机变成专用的网元设备，就能安心迁移，省心上云。于是Cisco出了ASR1k的VM Image，JUNIPER/HW/H3C也紧随其后。这个观点，我理解。但我觉得，这个不能作为把网络处理软件放在虚拟机的主要理由，因为显然这是一个过渡性技术，只不过方便客户上云而存在。而且设备厂商出这些Image并不仅仅只是为了这个而已。
如果说虚拟化能够让网络设备被Cloud系统得到管理，也被作为一种资源进行调用。那把NF放在虚拟机里面，显然是一种偷懒的做法。因为资源这种东西，不同的业务，有很多不一样的地方。表面上NF处理也是靠CPU，但是你能把这玩意等同于web处理吗？也许未来可以，但现在，我觉得不行。但是有一点，好像说清楚了，虚拟化，是为了更好的管理和调度。
说到这个，就不得不说服务链。其实这玩意根本不新鲜，只是以前没人叫服务链而已。我就问，难道以前的互联网公司没有服务链吗？通过控制路由，让流量依次经过lb/NAT/rate limiter，不叫服务链吗？企业里面的上网行为管理+FW+IDS，不叫服务链吗？那今天又提服务链是新瓶装旧酒吗？
我个人觉得，NFV的真正价值，在于把以前大家都觉得ok的事情拿出来批斗了一番：自动化和标准化。
啥是自动化？以前我们也有服务链，但是那个服务链是网工设计、运维手动搭建的，是一根根网线，一条条命令敲出来的。每次上下线网元设备，升级，流量导入导出，全部手动操作，网络设备直接command line，哇，真的是硬核摇滚式的网工时代。很多人说服务链的编排，服务链怎么编？我们首先得有个&amp;quot;博古通今&amp;quot;的控制器（controller），上能用存在了20年的netconf跟网络设备扯淡，下能用最新最酷的restful（其实对web来说也不酷了）跟管理端调情，中间什么ospf，bgp，ovsdb，了如指掌，跟谁都能谈笑风生。
把这些打通了，还仅仅是“术”，道是什么？是统一的模型，我现在想把A和B连起来，A是物理网关，B是一台虚拟机，我点两下鼠标就把这活给做了，中间跑了什么bgp协议，什么openflow，我不care。我现在想把两个service node下线了，也是鼠标点下就搞定了。所以说，得有个模型，没有模型，肯定搞不出来。
有了自动化的编排技术，我想把流量怎么引就怎么引，想让谁上线就让谁上线，然后就开始路由进行验证，检查服务链的流表规则会不会把那些不该丢的包给丢了，然后开始玩流的调度，保护客户体验，玩些细活。这是NFV的一种价值。
另一个点，我觉得很遥远，那就是标准化。什么是标准化，其实，把网元放虚拟机只是偷懒，是所谓IaaS的NFV，PaaS的NFV应该是把所有模块都标准化了，搭积木的干NF。这不是什么新鲜观点了，Click多少年前就号称是模块化的Router了，今天NFV的新意在哪？是假设网络中所有的硬件设备已经全部跑Click了。
想象一下，如果所有的设备都是一个相同的框架，会有那些有意思的事情发生？首先，迁移标准化了。网元设备的迁移是一个插件的拷贝，之前这有一台NAT设备，现在我把nat.so拷贝到另一台设备上，于是nat集群扩容了。第二，session同步标准化了，所有的集群设备自动化进行session同步，互为主备，自带多活，只要在写代码的时候写好流的状态信息，跑到时候自动互相备份流状态，哪一台crash了，都不会有啥问题。第三，调度细腻化了，我要下线某个NF，我只用下线某个模块，下线某个so，下线之后，设备上还有流量，只是流量会过别的so不会过这个NF。升级方便了，控制简单了。
觉得是胡说八道？其实很多老外lab已经做了，什么流迁移（flow migration），什么用编译器实现自动流状态管理（NSDI，paving the way to NFV），还有如何更好的code reuse，网络处理更高级的抽象，（NSDI， mOS，OSDI，netbricks，softNIC/Bess），也就是这几年冒出来的文章，这些都是NFV研究的一部分，也是NFV走向落地的一个信号。
所以说，NFV的价值在于，自动化的编排+标准化的代码。前者我认为已经在路上了，有了SDN的一些积累，编排是可能的，标准化应该也要开始了。只是这次标准化，应该是软件产品先行的，这次可能没有spec给厂商了，因为谁也不知道这个软件怎么写。这次，应该是先写一个框架，然后实现可迁移、模块可以随意调度，等到确实稳定可靠了，最后形成spec。
等到这一天，NFV就真的实现了。</description>
    </item>
    
    
    
    <item>
      <title>打造OpenContrail的一个开发沙盒(sandbox)</title>
      <link>https://xnhp0320.github.io/%E6%89%93%E9%80%A0opencontrail%E7%9A%84%E4%B8%80%E4%B8%AA%E5%BC%80%E5%8F%91%E6%B2%99%E7%9B%92sandbox/</link>
      <pubDate>Sun, 20 Aug 2017 20:25:49 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E6%89%93%E9%80%A0opencontrail%E7%9A%84%E4%B8%80%E4%B8%AA%E5%BC%80%E5%8F%91%E6%B2%99%E7%9B%92sandbox/</guid>
      <description>OpenContrail在中科院的时候接触过，那个时候还是个学生，书生气比较多（当然现在也很书生气）。当时觉得这玩意不够先进不够酷，其实就是没用OpenFlow，没用OVS，这两个潮流技术做数据面。到公司之后回过头来看，觉得真的是牛逼的不要不要的。
SDN的精髓，真的在控制器上，而控制器的精髓，不在于用了什么OpenFlow的技术，而是用统一的模型，描述网络的行为，真正牛逼的控制器，哪怕底层是一堆硬件交换机，他照样能够打造一个你想要的虚拟网。这个控制器能够干netconf/BGP/RESTFUL，无论你想怎么做，都能把底层给你收拾的服服帖帖的。于是终于明白OpenDayLight为啥有百万行的代码量。相比之下，contrail的控制器貌似只有十来万行，算精简了。
废话不多说了。今天找时间把OpenContrail的所有代码都down下来，想打造一个能跑的开发沙盒。记录下过程和踩的坑。
首先是途径问题。有两个途径，一个是下载contrail-installer，然后直接运行脚本，而是follow instructions。之前选择的是第一种方法，但是被一个apt-get问题卡住了。后来选择了第二种方法，其实殊途同归，同样是需要解决这个apt-get的问题。下面主要说下第二种方法怎么搞。
玩这种国外的大型开源软件（源代码有1.2G之大），最大的问题其实在于墙。第二种方法的问题也确实在这里。一开始就要用google的repo工具来管理代码。但是repo工具的官方原版需要从googlecode上下载repo工具，于是就被卡住了。花了两三个小时来解决虚拟机翻墙问题，后来无意中找到一个网页可以不从googlecode上下代码，而可以从github上下代码，问题三分钟就解决了。
然后就开始冗长的git clone，谢天谢地墙没把github给封了，不然国内的科研事业也会停滞好几年。中间出去打了两局游戏，回来的时候才发现下完。然后开始装一些安装包。我看了下，又卡在了apt-get问题上。
这个问题主要是需要更高版本的lz4软件包，但是源里没有。这里学到两个有用的命令：
apt-cache showpkg XXX
可以看出该软件包有那几个源提供，分别提供什么版本。
aptitude install XXX=Version
安装特定的软件包。
在网上特意找了一个高版本的lz4软件包，于是搞定了。就是这么简单。现在回过头来看，总结下就一条：
 采用国内的源是最好的，sohu的ubuntu源，豆瓣的pip源，然后github上的repo工具，完美。  接下来开始编译了，估计要编好几个小时。看来入手一个台式机已经是折腾技术的刚需了。</description>
    </item>
    
    
    
    <item>
      <title>Go 语言的初始化</title>
      <link>https://xnhp0320.github.io/go-%E8%AF%AD%E8%A8%80%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96/</link>
      <pubDate>Wed, 26 Jul 2017 22:13:59 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/go-%E8%AF%AD%E8%A8%80%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96/</guid>
      <description>Go语言的初始化有很多种形式，对照着C++其实可以体察出一些有意思的地方。我有一些猜想，也不知道对不对，记录下来。
##var与make Go语言Specification中规定:
 When storage is allocated for a variable, either through a declaration or a call of new, or when a new value is created, either through a composite literal or a call of make, and no explicit initialization is provided, the variable or value is given a default value. Each element of such a variable or value is set to the zero value for its type:
false for booleans, 0 for integers, 0.</description>
    </item>
    
    
    
    <item>
      <title>使用Lark解析常见的配置文件</title>
      <link>https://xnhp0320.github.io/%E4%BD%BF%E7%94%A8lark%E8%A7%A3%E6%9E%90%E5%B8%B8%E8%A7%81%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/</link>
      <pubDate>Sat, 22 Jul 2017 16:01:55 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E4%BD%BF%E7%94%A8lark%E8%A7%A3%E6%9E%90%E5%B8%B8%E8%A7%81%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/</guid>
      <description>最近公司上线新的软件，和老软件相比，配置文件有一些变化，这使得灰度的机器上的老配置文件不再适用，因而产生了一个新问题。如何将老配置文件转换成新的配置文件？本来这个并不是什么大问题，主要是对配置文件的语法解析比较麻烦。新老配置文件都是自定义了一种简单的语法，不是常见的json或者XML。软件内部解析这种配置文件也是手写了一个解析器。因此，需要手写一个转化脚本。我一直对这种解析很感兴趣，于是用python做了一个。
##选库 工欲善其事，必先利其器。用Python写的，支持特定文法的parser generator很多。我用了Lark，选择的原因其实很简单，文档比较全，看起来貌似很容易。一些专业的库一上来搞出一堆编译原理的术语，一般会吓退很多初学者。像我这种略知一二的自然只能放弃。Lark这个库我看了下，整体代码才2000行，小，而且最近一次commit是2017年，新，最关键的一点是，文档tutorial做的挺好，例子够全。所以就用他了。
##Rules 写这种parser generator的关键是先写好BNF的语法文件。这是我第一次写，试了很多次才成功。首先简单的介绍下配置文件的语法：
block valueA valueB valueC { key value block valueD valueE { } .... } 其本质上就是一个block里面的key value对，block里面能够嵌套block。第一次用BNF，试了好久。主要有几个问题：
  block的头部有不同的格式，比如block IP proto port 是一种，定义一个service，还有block IP port是另一种，定义一个real server。看到这两个术语，我估计有人已经猜到这一款什么软件了。
  语法解析的时候到底是否需要ignore whitspace么？这一点是借鉴了Lark自带的对Python语言解析的语法文件。我看他解析的时候都忽略了空格，那我这个简单的语法岂不是更可以忽略whitespace？
  如果选择忽略whitespace，问题就来了。key value这两个token就不好定义了。我本来觉得key应该定义成/[a-zA-Z-_]+/就可以了，结果发现有些key中还有数字。但是如果数字加上，这个key的正则表达式会直接吞掉value，因为忽略到空格之后key和value的定义几乎一致了，那么当parser设计的比较贪婪的时候，key本身的正则表达式就会把一行里面的key/value都吞掉。
  最终的解决方式是采用更精确的定义去做BNF。比如为每一种block做更精确的定义，我采用了比较笨的方法，因为反正整个配置文件就四种block，我每个都定义了一种。最终的配置文件：
conf : vs_block* vs_block : vs_head &amp;quot;{&amp;quot; vs_body* &amp;quot;}&amp;quot; _NEWLINE vs_head : &amp;quot;virtual_server&amp;quot; proto ip port tcp : &amp;quot;TCP&amp;quot; | &amp;quot;tcp&amp;quot; udp : &amp;quot;UDP&amp;quot; | &amp;quot;udp&amp;quot; proto : tcp | udp ip : /\d+\.</description>
    </item>
    
    
    
    <item>
      <title>临时变量？</title>
      <link>https://xnhp0320.github.io/%E4%B8%B4%E6%97%B6%E5%8F%98%E9%87%8F/</link>
      <pubDate>Mon, 17 Jul 2017 22:37:33 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E4%B8%B4%E6%97%B6%E5%8F%98%E9%87%8F/</guid>
      <description>在2017-7-02的日志中存疑的地方在于，貌似folly库用了一种方法把所有的值都变成了左值引用。
当时用了一个小程序来推测这个问题：
auto transform(std::string &amp;amp;&amp;amp; a) { std::cout &amp;lt;&amp;lt; &amp;amp;a &amp;lt;&amp;lt; std::endl; return std::ref(a); } int main() { auto a = transform(&amp;#34;hahaha&amp;#34;); std::string &amp;amp;r = a.get(); std::cout &amp;lt;&amp;lt; &amp;amp;r &amp;lt;&amp;lt; std::endl; r[0] = &amp;#39;b&amp;#39;; std::cout &amp;lt;&amp;lt; r &amp;lt;&amp;lt; std::endl; } 实际上，这里&amp;quot;hahaha&amp;quot;是一个右值，而且会生成一个临时对象std::string，并用这个临时对象来初始化a，但是是否这个临时对象的生存期就在transform这个函数中呢？如果如此，那么该程序会core掉。
实际上改成如下程序之后，程序确实core掉了：
std::string &amp;amp;&amp;amp; make_string() { return &amp;#34;hahaha&amp;#34;; } auto transform(std::string &amp;amp;&amp;amp; a) { std::cout &amp;lt;&amp;lt; &amp;amp;a &amp;lt;&amp;lt; std::endl; return std::ref(a); } int main() { auto a = transform(make_string()); std::string &amp;amp;r = a.</description>
    </item>
    
    
    
    <item>
      <title>C&#43;&#43;值的分类</title>
      <link>https://xnhp0320.github.io/c-%E5%80%BC%E7%9A%84%E5%88%86%E7%B1%BB/</link>
      <pubDate>Sun, 16 Jul 2017 21:34:24 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/c-%E5%80%BC%E7%9A%84%E5%88%86%E7%B1%BB/</guid>
      <description>本文根据这篇文章整理而成。
C++的值有两个正交的特性：1）有名字，其实就是可以取地址；2）可以从别的地方移动过来（can be moved from）；有名字用i表示，没有用大写的I，可以移动用m表示，不能移动用M。那么C++的值有以下几个分类：
1）iM: 有名字，但是不能从别处移动过来。
2）im: 有名字，可以从别处移动过来。
3）Im: 没有名字，但是可以从别处移动过来。
这些值的关系如下图所示：
首先，在C++中，任何值不是左值就是右值。
其次，左值不是右值，右值不是左值。
在图中可以看到，这些值的特点构成一个W形状，左边这条腿是左值，右边这两条腿是右值。
那么C++中的左值在上图中到底对应什么？目前来看应该是iM，即有名字，但是不能从别处移动得来，这个也比较自然。因为在C++11之前，啥都是不能移动的。那么i是什么？i表示generalized lvalue，即比较通用的左值。这个也符合C++的定义，在C++中只要有名字的就是左值，称之为glvalue。
那么什么是右值？在C++11之前，右值语义最想解决的问题是资源的移动。那么右值应该就是可以被移动的，而且一般这种右值是没有名字的，比如临时产生的变量，这种，我们称之为prvalue，即纯右值。而m表示一般右值。
那么最后的一个问题来了，W中间这个im表示是啥？即有名字，又可以移动。那么只能是一个右值引用了。因此称之为xrvalue。C++11称之为将亡值。
来看几个例子：
std::string get_str() { return &amp;#34;hahaha&amp;#34;; } std::string&amp;amp;&amp;amp; get_str() { return &amp;#34;hahaha&amp;#34;; } 在C++中，第一个get_str返回的是prvalue，是一个纯右值，可以移动但是没有名字。但是第二get_str返回是xrvalue，是右值，但是有名字。区别在于：
const std::string &amp;amp; str = get_str(); //第一个返回的对象的生命期可以延续  const std::string &amp;amp; str = get_str(); //第二个返回的对象实际已经销毁了，这里str引用指向的对象已经没有了。 这是因为C++标准规定了，temporaries die at the end of the statement, unless they are bound to const reference, in which case they die when the reference goes out of scope.</description>
    </item>
    
    
    
    <item>
      <title>C&#43;&#43;初始化笔记</title>
      <link>https://xnhp0320.github.io/c-%E5%88%9D%E5%A7%8B%E5%8C%96%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Fri, 14 Jul 2017 22:12:32 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/c-%E5%88%9D%E5%A7%8B%E5%8C%96%E7%AC%94%E8%AE%B0/</guid>
      <description>符合以下规则：
 默认构造函数（使用类内初始值和默认值，如果没有类内初始值，而且不是静态类型，一般是残值） 有定义构造函数，则不合成默认构造函数，除非使用=default 构造函数初始值列表进行初始化 构造函数内部，进入构造函数内部，所有成员已经完成初始化，对成员进行后续操作可以看成是一个函数在进行初始化。  下面的代码，初始化逻辑：
 进入到构造函数内部之后，所有的成员变量都已经完成了初始化。此时，成员b采用默认构造函数进行初始化。打印第一个 default 使用默认构造函数创建一个临时对象B()，打印第二个 default。 B() 是一个右值，所以调用右值赋值函数，但是由于B的移动构造函数是删除的，所以只能使用拷贝赋值函数 B&amp;amp; operator=(const B&amp;amp;) 来作为备选，本来一个const B&amp;amp; 也可以指向一个临时的右值 B()。 使用赋值拷贝函数，将临时对象B()拷贝给成员b。打印 B assign  #include &amp;lt;iostream&amp;gt; struct B { //default ctor  B() { std::cout &amp;lt;&amp;lt; &amp;#34;B default &amp;#34; &amp;lt;&amp;lt;std::endl; } //copy ctor  B(const B&amp;amp;) { std::cout &amp;lt;&amp;lt; &amp;#34;B copy &amp;#34; &amp;lt;&amp;lt;std::endl; } B&amp;amp; operator=(const B&amp;amp;) { std::cout &amp;lt;&amp;lt;&amp;#34;B assign &amp;#34;&amp;lt;&amp;lt; std::endl; return *this; } B(B &amp;amp;&amp;amp;) = delete; B&amp;amp; operator=(B &amp;amp;&amp;amp;) { std::cout &amp;lt;&amp;lt;&amp;#34;B move &amp;#34; &amp;lt;&amp;lt; std::endl; return *this; } }; struct A { B b; A() { b = B(); } }; int main() { A a; } ##三五法则</description>
    </item>
    
    
    
    <item>
      <title>folly ScopeGuard.h 分析</title>
      <link>https://xnhp0320.github.io/folly-scopeguard.h-%E5%88%86%E6%9E%90/</link>
      <pubDate>Sun, 02 Jul 2017 14:01:43 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/folly-scopeguard.h-%E5%88%86%E6%9E%90/</guid>
      <description>先把folly/ScopeGuard.h的前118行放在这里：
namespace folly { class ScopeGuardImplBase { public: void dismiss() noexcept { dismissed_ = true; } template &amp;lt;typename T&amp;gt; FOLLY_ALWAYS_INLINE static void runAndWarnAboutToCrashOnException( T&amp;amp; function) noexcept { try { function(); } catch (...) { warnAboutToCrash(); std::terminate(); } } protected: ScopeGuardImplBase() noexcept : dismissed_(false) {} static ScopeGuardImplBase makeEmptyScopeGuard() noexcept { return ScopeGuardImplBase{}; } template &amp;lt;typename T&amp;gt; static const T&amp;amp; asConst(const T&amp;amp; t) noexcept { return t; } bool dismissed_; private: static void warnAboutToCrash() noexcept; }; template &amp;lt;typename FunctionType&amp;gt; class ScopeGuardImpl : public ScopeGuardImplBase { public: explicit ScopeGuardImpl(FunctionType&amp;amp; fn) noexcept( std::is_nothrow_copy_constructible&amp;lt;FunctionType&amp;gt;::value) : ScopeGuardImpl( asConst(fn), makeFailsafe(std::is_nothrow_copy_constructible&amp;lt;FunctionType&amp;gt;{}, &amp;amp;fn)) {} explicit ScopeGuardImpl(const FunctionType&amp;amp; fn) noexcept( std::is_nothrow_copy_constructible&amp;lt;FunctionType&amp;gt;::value) : ScopeGuardImpl( fn, makeFailsafe(std::is_nothrow_copy_constructible&amp;lt;FunctionType&amp;gt;{}, &amp;amp;fn)) {} explicit ScopeGuardImpl(FunctionType&amp;amp;&amp;amp; fn) noexcept( std::is_nothrow_move_constructible&amp;lt;FunctionType&amp;gt;::value) : ScopeGuardImpl( std::move_if_noexcept(fn), makeFailsafe(std::is_nothrow_move_constructible&amp;lt;FunctionType&amp;gt;{}, &amp;amp;fn)) {} ScopeGuardImpl(ScopeGuardImpl&amp;amp;&amp;amp; other) noexcept( std::is_nothrow_move_constructible&amp;lt;FunctionType&amp;gt;::value) : function_(std::move_if_noexcept(other.</description>
    </item>
    
    
    
    <item>
      <title>C&#43;&#43;的右值引用的几个坑</title>
      <link>https://xnhp0320.github.io/c-%E7%9A%84%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8%E7%9A%84%E5%87%A0%E4%B8%AA%E5%9D%91/</link>
      <pubDate>Mon, 03 Apr 2017 08:56:52 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/c-%E7%9A%84%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8%E7%9A%84%E5%87%A0%E4%B8%AA%E5%9D%91/</guid>
      <description>有名字的一定是左值；能取地址的一定是左值。这一点最坑：  int &amp;amp;&amp;amp; a = 1;
请问a是左值还是右值？a有名字，因此a是左值，a是一个右值引用，a和1 绑定。
int i = 0; int &amp;amp;&amp;amp; a = i+1; a是一个右值引用，指向一个临时对象，那么a是右值么？不是，是左值，而且可以对a取地址。
std::cout &amp;lt;&amp;lt; &amp;amp;a &amp;lt;&amp;lt; std::endl;
 T&amp;amp;&amp;amp; 有时候是右值引用类型，有时候是universal reference  什么意思？因为C++给T&amp;amp;&amp;amp;开了特例，允许给T&amp;amp;&amp;amp;传入一个左值，并根据折叠规则(T&amp;amp;&amp;amp; &amp;amp; = T&amp;amp; T&amp;amp;&amp;amp; &amp;amp;&amp;amp; = T&amp;amp;&amp;amp;)进行类型推断。因此T&amp;amp;&amp;amp;是万能的reference，即universal reference。对universal reference有一个判断标准：
 If a variable or parameter is declared to have type T&amp;amp;&amp;amp; for some deduced type T, that variable or parameter is a universal reference.
 什么意思？如果一个变量或者函数的形参T&amp;amp;&amp;amp;需要类型推导，那么他一定是universal reference。举个栗子：
template &amp;lt; typename T &amp;gt;	void fuck(T&amp;amp;&amp;amp; t) {} 这个t是universal reference，因为他什么都接，可以是左值，也可以是右值，但是根据上一条规则，t本身是一个左值!</description>
    </item>
    
    
    
    <item>
      <title>一致性哈希算法一些认识</title>
      <link>https://xnhp0320.github.io/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E4%B8%80%E4%BA%9B%E8%AE%A4%E8%AF%86/</link>
      <pubDate>Fri, 03 Mar 2017 14:29:01 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E4%B8%80%E4%BA%9B%E8%AE%A4%E8%AF%86/</guid>
      <description>当负载均衡后端服务器数量发生变化时，可能会导致本该发给RS1的数据包发送到RS2。此时有两种解决方案：1）采用session，记录建立的连接选择的后端服务器。2）采用一致性哈希，一致性哈希可以保证当后端服务器数量发生变化时，分配给连接已经建立的数据包的后端不会发生变化。
经典一致性哈希算法 经典一致性哈希算法将哈希空间看成一个环，每条流被哈希成环上的一个单点。此时将RS也哈希到环上，这些RS对应的点将哈希环分拆成几个部分，通过某种规则将各个部分分配给不同的点，比如逆时针碰到的第一个RS点，就是被分配到的RS。因此从这个角度来看，经典一致性哈希的均衡性在于RS的哈希点分布的均衡性，如果RS哈希点分布均衡，那么一致性哈希一定是即均衡且当后端RS数量变化时，受影响的session更少。通常的做法是将一个RS哈希多次到环上。这样能保证RS能更均衡的散布在环上。
Google Maglev一致性哈希 其做法是将均匀性至于minimal disrupt之上，根据前几篇blog可以看出，Google Maglev的算法是最均衡的，因为他能完全均分hash array（也就是哈希空间），但是通过permutation表，尽量降低哈希的碰撞率，在碰撞率小的时候，能够保证位置不会被多个表项所抢占。</description>
    </item>
    
    
    
    <item>
      <title>对ip_vs中rcu锁和timer之间的竞态关系的分析</title>
      <link>https://xnhp0320.github.io/%E5%AF%B9ip_vs%E4%B8%ADrcu%E9%94%81%E5%92%8Ctimer%E4%B9%8B%E9%97%B4%E7%9A%84%E7%AB%9E%E6%80%81%E5%85%B3%E7%B3%BB%E7%9A%84%E5%88%86%E6%9E%90/</link>
      <pubDate>Sat, 01 Oct 2016 11:46:42 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E5%AF%B9ip_vs%E4%B8%ADrcu%E9%94%81%E5%92%8Ctimer%E4%B9%8B%E9%97%B4%E7%9A%84%E7%AB%9E%E6%80%81%E5%85%B3%E7%B3%BB%E7%9A%84%E5%88%86%E6%9E%90/</guid>
      <description>对内核ip_vs模块中的流表之间的竞态关系做了如下分析。
  RCU锁只能保护在read_lock/unlock之间对cp的引用，而不能保护在读锁之外的区域。因此，如果有人在读锁之外继续使用cp指针，则只能使用引用计数保护。
  内核2.6.32采用读写锁，因此在读写之间本身是互斥的，所以直接使用inc和dec。而使用RCU锁，读写可能同时出现，因此必须用原子操作互斥。因此get使用atomic_inc_not_zero，put因为跟get配对使用，直接减1，而timer中使用atomic_cmpxchge。因为原子变量互斥，效果和读写锁类似。因为这种互斥性，当cp从hash表中删除，local_in和out的勾子函数不可能持有cp。只有使用drop_randomentry的线程可能会持有cp。因此个人感觉使用RCU锁似乎没有比用读写锁占到更多的便宜？
  timer中，如果引用计数为0，是否一定没有对cp的引用？不一定。可能此时当前这个timer已经被重新激活，在未来某个时候expire，相当于此时cp已经又被一个timer所引用。在当前timer_expire函数中要避免这一点，因此需要在确定释放cp前，调用del_timer。内核2.6.32和3.10都这么做了。
  因而当timer处于pending状态时，是否call_back一定没有被执行？不是，因为在call_back刚开始被执行时，有其他线程把timer重新激活了。此时timer处于pending状态，而且timer的callback还在执行。这是timer最复杂的地方。
  那么是否同一个timer的callback函数会在不同的两个核上运行？不能，因为每次mod_timer时，会检查timer的base—&amp;gt;running_timer，如果不等于timer，说明timer callback没有运行，那么可以把timer迁移到mod_timer的核，否则，当timer callback在运行的时候，则只能把timer挂载到之前挂载的核。因此一个timer的callback不可能会在两个核上同时运行。
  timer只有一个，他要么就是pending要么就是expire或者即将调用callback然后expire。当在timer中引用计数为0，并且已经del_timer，此时，是否有其他线程能够重新mod_timer? 不可能，其他线程获取cp时，要么引用计数大于0（不满足，因为在get时，引用计数不为0才能增加引用计数并返回cp指针），要么mod_timer时，需要timer是pending状态（比如expire_now函数），此时timer刚被del_timer，因此也不满足，因此，此时可以安全的释放cp。
  上述条件实际上暗示了，并不一定需要获得引用计数才能对timer进行修改。现在解释为何expire_now函数不需要引用计数的保护。当mod_timer在read_lock/unlcok保护区时，cp不会被释放，因此可以安全的访问cp-&amp;gt;timer。而此时，如果timer处于pending状态，有两种可能，要么callback没运行，那么就改掉。要么callback正在执行，此时如果mod_timer会有导致timer被重新激活，并只能在当前核等待callback运行完之后expire，因此只需要保证在callback函数中del_timer之前完成调用mod_timer调用便是安全的。实际上，使用del_timer之后，mod_timer_pending一定会失败，因为如果之前mod，timer会被删掉，如果之后执行mod，此时timer已经被删掉了，不是pending状态，同样会失败。
  </description>
    </item>
    
    
    
    <item>
      <title>书店</title>
      <link>https://xnhp0320.github.io/%E4%B9%A6%E5%BA%97/</link>
      <pubDate>Fri, 05 Aug 2016 21:07:47 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E4%B9%A6%E5%BA%97/</guid>
      <description>在某个城市短暂的停留，有时间但时间又不够的时候，书店是一个好的去处。如今这个时代，去书店往往意味着在时间和金钱上的全面奢侈，因而去书店也就不单单意味着买书，还有散心和陶冶情操的双重功效。有些书店因此就顺势而为，把自己打造成某种文艺生活方式的朝圣地，吸引众多文艺青年的聚集。毕竟在网上鼠标下单，即摸不到书皮，也闻不到墨香，更看不到陈列，有时候你看中了一本书，边框上还冒出一堆推荐，就像个不怀好意的店员在一旁跟你一直唠叨，“先生，很多人看了这个书之后又买了那本书哦，你要不要试试？”，想想也觉得挺烦的。
很多年以前，我去单向街书店。刘瑜和一个叫熊什么的意见领袖做讲座，讲着很高大上的话题，很多人慕名前往，把一个小小书店挤得水泄不通。刘瑜他们当天说了些什么我早都忘了，但是却开始注意在书店工作的店员们。多数是妹子，模样都清丽干净，不算漂亮但肯定也不丑，身穿素雅的店服，语气大多小声温柔。在摆书的时候，还会振振有词臧否作家，“放这么多村上在这里干什么，难卖！”，“要不要再进几本三岛由纪夫，最近好像很火的样子?”&amp;hellip;&amp;hellip;
这些年进了很多书店，也看了不少互联网新闻，老在想，这些年轻人选择在书店工作，或许是不得已，或许就是一种喜好。书店也是一个公司，也是要盈利的地方，可从来不是财经杂志和资本市场垂青的对象。毕竟，书店的店长不可能像海底捞那样要求店员给每个进店选书的提供无微不至的服务，因此也写不出《雕刻时光你永远也学不会》；自己就是要被颠覆的对象，所以也没法动不动就融资好几亿好几亿。
书店只能躺在那里，越安静越好。它能提供的服务，反而是一种克制。店员给客人的感觉恰恰应该是熟视无睹、来去自如、任君品阅。这种克制，有时候让人觉得有点傲娇：满墙的经典，你爱读不读；有时候又有些温情，读书永远不是一件过时和太晚的事情，焦虑了，就来这里寻找一点安全感。
这些年，总觉得自己愈发浮躁。买了很多书，就看了个序。满书柜的书，看过三分之一的就算不错了。有心情读的时候，也不像在读，而是在找，满页满页的找，找什么自己也不知道。在书店选书的时候，心里也在算，这本是经典，网上肯定有电子版，买了不划算；这个作家最著名的书还躺在我书架上，新出的这本还是别买了吧。盘算下来，每每饱含希望而来，最后失望空手而归，好像整个书店的书都不值得一读了。
好在书店不会跑，下次去的时候，还可以再努力的挑一次。你看，这也是书店有一个好处，你永远都能再去一次。</description>
    </item>
    
    
    
    <item>
      <title>Maglev一致性哈希（补遗）</title>
      <link>https://xnhp0320.github.io/maglev%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E8%A1%A5%E9%81%97/</link>
      <pubDate>Tue, 28 Jun 2016 09:41:57 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/maglev%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E8%A1%A5%E9%81%97/</guid>
      <description>上篇blog介绍的一致性哈希算法满足minimal disruption和load balancing两个特性。其实有更简单的方法满足这两个条件。我们知道，构造哈希函数本质是填数组（fill the entry[])，那么要想得到load balancing的数组，只需要后端backend依次填入数组就肯定是balancing的。比如
 entry[0] = B0
entry[1] = B1
entry[2] = B2
entry[3] = B0
&amp;hellip;
 当需要删除一个backend时，将对一个的表项全部remove，然后这些空出来的表项可以被均分给剩下的backends。同理，新增一个backend也可以采用类似方法处理。从这个角度来看permutation table本来也没存在的必要。
我后来写信给Google的人，他们给出一个非常有道理的回复：
 You are correct that with one load balancer, the technique you described would be simple and work optimally. However, the lookup table would be dependent on history. Two (or more) load balancers that started at different times or saw events in different orders would end up with different tables, and traffic that moved from one to another would not get the same assignment.</description>
    </item>
    
    
    
    <item>
      <title>Maglev中的一致性哈希算法</title>
      <link>https://xnhp0320.github.io/maglev%E4%B8%AD%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/</link>
      <pubDate>Sun, 26 Jun 2016 10:21:13 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/maglev%E4%B8%AD%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/</guid>
      <description>Maglev是Gogole在NSDI 2016上公布的其内部使用的软件负载均衡系统。论文关于系统架构已经说得很清楚了，除了其中一致性哈希算法部分，看着略犯晕。本文简要介绍下这个系统中的一致性哈希算法。
负载均衡系统 负载均衡系统基本上只要是做互联网的公司都要用到。其原理，我感觉就是个大哈希表：对外网（WAN）只宣告几个虚拟IP地址（VIP），而把客户端的流量通过哈希表做连接跟踪，将流量负载均衡到后端（backend）大量的服务器集群上。基本上各大互联网公司都有一套自己的负载均衡的系统。现在托云计算的福，很多小的公司也可以直接使用其云计算的IaaS功能实现的负载均衡器。
关于负载均衡系统，国内有个著名的开源人物章文嵩开发了LVS，想必做网络开发的都基本上耳熟能详。章文嵩在2002年的时候做的LVS，当时是基于内核做的开发。当年的网络开发的潮流就是想要高性能就得玩内核。时过境迁，当DPDK这种技术已经开始普及，bypass-kernel成为新潮流。所以，似乎目前有些公司开始研发全用户态的负载均衡系统，比如Vortex。
Google的Maglev应该做的时候还没有DPDK，但看论文也是bypass-kernel。目前网络已经一坨坨的bypass kernel了，存储也在路上。所以说，bypass-kernel 已经是 the new sexy了么？
一致性哈希 一致性哈希在网络、文件系统、中间件中都有用到。其主要解决当后端服务器的个数出现变化的时候，如何通过哈希机制继续保证剩下的服务器之间负载均衡。负载均衡系统的后端服务器集群可能时常面临服务器负载过高而挂起、服务器系统升级、服务器容量升级等原因而产生的服务器数量的变动，这个时候一致性哈希就有了用武之地。比如一个服务器A过载挂了，之前被分配到A的流都需要被重新分配（re-shuffle），一致性哈希需要保证被重新分配后的流能够尽量均衡的分配到其他的服务器上，而不至于造成新的过载。比如新增一个服务器B，一致性哈希需要保证对已有分配结果进行最小限度的修改，同时要保证分配后的均匀性。
Maglev的一致性哈希算法 首先说说一致性哈希算法的本质：说白了，就是一个哈希函数（注意，不是哈希表)，输入是一个流，输出是这个流所对应的后端服务器。
 Hash(flow1) = 服务器A
Hash(flow2) = 服务器B &amp;hellip;
 当有数据包进入，Maglev首先check本地的连接跟踪表，看看该数据包是否属于任何一个已有的连接，如果连接已经建立，则直接将数据包发到该连接对应的服务器上去。如果连接没有建立，此时就需要一致性哈希函数选择一个后端服务器了。
一致性哈希函数可以通过一个数组Entry[]的方式构造，假设数组长度为M，那么对应流F的后端服务器为：
 Entry[Hash(F) % M]
 Maglev的一致性哈希算法本质上设计算法让每个后端按照一定的规则去填满数组Entry[]中的empty slot，确保所构造出来的数组Entry[]的元素中，所有后端服务器出现的次数尽可能相等。这个数组Entry[]就是最终所以使用的一致性哈希函数。
为了设计填充规则，Maglev首先给每个后端服务器i设计了一个permutation表。permutation表存储一个0到M-1的随机排列，比如当Entry数组长度M=7时，permutation表内容可以为：
 3 0 4 1 5 2 6
 这个permutation表实际上是用来构建抢占规则的。 对于每个后端服务器i，Maglev通过以下方式生成permutation[i]:
实际上，上图中的skip，offset还有哈希后端服务器名字都只是一种随机化的方法，用于构造permutation表而已。
紧接着，使用以下算法构造Entry表。
这个算法实际上就是，对于每个服务器后端i，通过其permuation[i]表所设立的规则，在entry数组中寻找empty slot，当发现被slot被填时，不停使用next[i]+1的方式跳到entry[permuation[i][next[i]]中probe是否有empty slot，一旦发现有empty slot则把empty slot分配给自己，即算法中entry[c] = i。通过这样的方式，每个服务器都有机会去填一个空位，当最终填满entry[]表时，所构造出entry[]数组一定是均衡的。
假设M=7，即数组entry[]的长度为7，有三个后端服务器B0、B1、B2，其permuation表如下图所示。根据上述算法，首先entry[]表是空的，B0来填，根据其permuation表，首先看看3的位置是不是空，发现是，于是entry[3] = B0。然后B1来填entry[]，于是entry[0]=B1。最后B2来填表，他首先看entry[3]，发现已经填了B0，于是看下一个位置，4，于是entry[4]=B2。
上图同时显示了，当B1被remove之后，所构造出来的entry表，可以发现后端服务器出现的次数是完全一样的，达到了均衡的目的。</description>
    </item>
    
    
    
    <item>
      <title>一些感想</title>
      <link>https://xnhp0320.github.io/%E4%B8%80%E4%BA%9B%E6%84%9F%E6%83%B3/</link>
      <pubDate>Fri, 01 Apr 2016 23:32:27 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E4%B8%80%E4%BA%9B%E6%84%9F%E6%83%B3/</guid>
      <description>能持续输出文字的人肯定是有趣的人。我们中的大多数，一般也就满足于一日三餐，饱食终日。天天写字的人至少还能思考，还能将思考的过程流于笔端。若不局限于伤春悲秋的情绪记录，还能有知识或者经验分享的价值，具有知识传播、增添情趣的意义。
笔耕不辍，除了话唠嘴碎，还有一种可能是经历实在太丰富。人活一世，在世界行走一遭。有的人生故事三分钟就能说完，有的人生故事三本书都说不完。然而人终究是局限的，不可能体验所有。
想想真觉得遗憾。</description>
    </item>
    
    
    
    <item>
      <title>再见，2015</title>
      <link>https://xnhp0320.github.io/%E5%86%8D%E8%A7%812015/</link>
      <pubDate>Sat, 16 Jan 2016 22:45:42 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E5%86%8D%E8%A7%812015/</guid>
      <description>真正想写点什么东西的时，和能找到时间瞎写点什么时，往往不是一个时候。比如现在，总感觉时间有了，但是感触消失了。前段时间特别想回顾法国的日子，每当回想总是历历在目，现在想来却全是模糊的，找不到感动的点。所以每一次的有感触的时候总是很珍贵的。你要知道，如果哪天你放弃了这些感触，她们也会放弃你。当对生活的敏感消失，你的文艺才能也就消失了。
我的2015年，发生了很多事情。但是最重要的事情，往往不是重要的项目、成果、论文、投资，而是不经意间发现生活的真相。我有时候觉得生活真的很无聊，也很残忍，而你真正能超越这些繁琐和计较的时刻，只有你在创造和思考的时候。人类靠着创造中的未来，不存在的远方和诗意，伟大的故事和传奇活到了现在。期望总是美好，收获总是太少。客套总是太多，真话总是太少。
我一次次问我自己，我到底要的是什么，钱？权？名？好像都不是必须的。这种人最难伺候，欲望总是不具象化。有个CTO跟我说，有的人一生下来就知道自己要干什么，他回望自己的技术和创业生涯，感觉这是最重要的，哪怕是我生下来就想要开个小饭馆呢？如果一直努力那也成了。这就是我的2015年最大的问题，做事太多太杂，没有主线，对自己也缺乏定位，这当然也有老板安排的问题。不说了。可所有的东西，金钱权力美女都是争来的，如果没有利益和好处，都会离开，这样的生活想起来的时候会不会有点失落呢。人就是很奇怪的一种动物，明知自己打着算盘却想着别人全心付出。这是不是很自私呢？所以，朋友不靠谱，亲戚不靠谱，小孩是最亲的，孩子必须有。从这个角度来看，传宗接代是不是在没有信仰的年代人们一种信仰的寄托？？？最近真的对人这种动物这种社会性的由来想太多了。
2015年，本来我以为我要虎一把，结果是又苦了一把。2016年是要顺一把，还是要溜了呢？
2015年，做过开发、keynote speak，写过本子，投过论文，被拒过论文，混过开源。曾经有的人说人到世间这一辈子，每经历一点就是赚一点，经历越多就是赚的越多。那我的2015年是赚了？
Anyway, farewell, 2015.
一样的月光</description>
    </item>
    
    
    
    <item>
      <title>Hard Feelings</title>
      <link>https://xnhp0320.github.io/hard-feelings/</link>
      <pubDate>Fri, 04 Sep 2015 22:45:51 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/hard-feelings/</guid>
      <description>距离上次写post转眼三个月过去了。 这三个月我想的事情，好像超过了最近三年内发生的事情。 当然我不想一开头就把氛围搞的很感伤，然而事实上我就是很感伤。主题自然还是那些old stuff，hard feelings，sad mood，life is tough，etc. 被人类写了一千年，还将继续被写下去。
So now，我要贡献我的版本。我怕写在朋友圈会又会传播负能量。好在现在有了这里，一块隐秘的负能量的自留地。
年轻人告别年轻基本上是必然的。从某个时段开始，那些轻狂的时光突然就和你没有任何关系，而且你还觉得自己懂得了道理，主动放弃了那种生活。你开始厌倦在KTV里面声嘶力竭，在人群里面故作姿态。看以前写的东西会脸红，做任何事情都开始思考目的，计算得失。没有什么说走就走的旅行，甚至你开始怀疑旅行的意义。指着地图上，我到了这里， 我到了那里，然后怎样？有什么用？去年的照片，前年的明信片，到不了，回不去，怀念又能如何。
那些年轻时认可的人渐渐面目模糊。当年很喜欢老罗，最近发现很久没看过他的微博了。现在回想起来，老罗，作为一个段子手是合格的，作为一个企业家，简直是出格的。当年创办英语培训学校，带了一帮人出来做事，结果才干了两年就转行做手机了，这难道不是一种不负责任？对投资人，对当时带出来一起创业的同事？现在终于学会了收敛，现在看来，原来当初自己欣赏的家伙竟如此任性，说走就走，担当何在？现在对很多事情的看法都改变了，忽然就明白了世界是灰的，不白也不黑。比如当年很火的厦门人民散步事件，很多人激动的说这是中国历史上第一次公民意见自发的表达并让政府妥协的事件。结果呢？很多年后，清华的学子和网民争论到底PX化学物到底是低毒还是剧毒。由于各地人民反对建立PX工厂，这种工业原料严重短缺，反而导致更多问题。有时候想起还真觉得有点像胜利既是正义中堺雅人的观点。从开头到现在，到底谁在混淆是非？谁在煽动群众？究竟谁有权判决一件事是对还是错？是正义还是邪恶？还有现在的高铁，当初出了事情之后，网上好多人号称自己是工程师发帖吐槽说此生不会坐高铁，说高铁多么多么不安全。结果呢？高铁改变了中国。现在谁出门不走高铁？究竟什么是理想主义，谁又在贩卖情怀？
也许这就是所谓的成长，你慢慢看清些东西，也慢慢开始有了偏见。对世界的想象渐渐被消除，而替代的有可能只是你的另一种狭隘的见解，慢慢的，你成了一个保守主义的人，怀疑所有新生事物，站到了年轻人的对立面。有句话，当你觉得自己已经对世界足够重要的时候，世界才刚刚原谅你的幼稚。说这话的是陈凯歌，你一定难以想象他还能如此文艺，说出如此深奥的道理。这些年，我们看着他拍无极，拍搜索，拍道士下山，慢慢开始怀疑霸王别姬是他爸拍的。正如我们开始怀疑开着赛车风一样的男子韩寒的文字是出自他爸的手笔。年少时好多你觉得正确的道理，现在又开始动摇，为什么你成了这样，他成了那样？韩寒、老罗、冯唐，那些年少时候的英雄，现在一个一个的失去兴趣；大众创业，万众创新，多么激情的口号，如果是当年肯定操起家伙就开干了。
不敢说以前认同的事情都是错的。但是现在好像比以前谨慎了很多。好像越活越不明白了，又好像越活越明白了。
长不大的人，都是因为要的太多。最大的遗憾，是不同步，好多道理，我明白得太晚了。
Prelude</description>
    </item>
    
    
    
    <item>
      <title>科研的故事</title>
      <link>https://xnhp0320.github.io/%E7%A7%91%E7%A0%94%E7%9A%84%E6%95%85%E4%BA%8B/</link>
      <pubDate>Sat, 13 Jun 2015 19:59:23 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E7%A7%91%E7%A0%94%E7%9A%84%E6%95%85%E4%BA%8B/</guid>
      <description>这是一个悲伤的故事。而且，还很长。
2012年 照理说，投稿的，任何一次顶会截稿之后，人都会心情愉快。
搞研究人的应该能够理解这个以上这个说法，拼死拼活，字斟句酌，文字要骚，图表要屌，实验要酷，十八班武艺全用上了，要提交了，临门一脚，终于射了（咳咳）。但是这次投完CoNext之后我却没啥感觉。真的没感觉。
想起第一次投SIGCOMM的时候，还觉得记忆犹新，但是其实已经是将近两三年前的事了。熬了一个通宵，在将近4点的时候睡着了，然后又惊醒，然后又开始改，最后到了五点的时候，法国老板来了句，算了没戏了，下次吧。这就好比，临门一脚，但是没踢到球一样，子弹没出来。但那个时候还是很开心，第一次在实验室看到了日出，第一次觉得自己也能做出可以试试SIGCOMM的成果，下楼会宿舍的时候那内心的澎湃，脚步轻盈，好像刚刚从洗脚城出来一样。然后，就没有然后了。投都没投，还有个屁的然后。
现在回过头来想，真的太不容易了。从2012年3月出国，8月底回国，快回国的时候我才开始真正做点所谓科研的东西。之前一直在游荡，像一个孤魂野鬼，没人指导，找不到方向。原本以为出国跟着法国老板会有所改善。我还清晰的记得，有次他很严肃的跟我说，“Peng, you are a very tanlented student, you can do research by yourself!”，当时内心悲愤，“尼玛根本不管我就算了，还他妈说这种话来恶心我”，差点就要拍案而起，直接开干。在回国前暂住的酒店里我还在敲代码做实验，后来同门说，他以为，我这么骚的一个人，肯定会在离开法国的时候肯定会来一篇散文，缅怀这过去的6个月的异国时光，我什么都没说。有些事情事后可以调侃，事中都只能深深的无奈。
回国之后，时差都没来得及倒过来，又跑到南京搞工程，说是做代码，但也没有分到实际的活，每天还是在那里调算法。在回国之前，其实只是有一个想法的雏形，然后开始匆匆上马实现。无奈算法功底也不行，好容易做出一个算法出来，看到TON 2012上有一篇论文想法跟我高度重合，而且人家的解法还更elegant。沉重的打击后浑浑噩噩的过了一两个月，发现实在是没法改进了。之前的论文都写了七八页，还是放弃了以前的思路。直到有一天突然灵光一现，既然不能超越已有算法，但已有算法也不是在所有场景下都牛逼，我要做一个甄选机制，挑选出最牛逼的，这样反而能避开和已有方法的直接比较。这就好比参加中国好声音，对手都太他妈强了，实力都不分伯仲，但有的擅长爵士，有的擅长摇滚，哥本来也是选手，突然华丽转身变成评审了，这就没必要跟选手比来比去了。当时就拿起笔开始一顿狂写，还记得当时新年元旦三天假，一起住的同学都回北京了，就我一个人在南京的房间里，像个疯子一样喃喃自语，奋笔疾书了三天，现在想想真的有点破釜沉舟的感觉。
然后就发生了开头的一幕，到了最后要投稿的时候，导师说你的想法很妙，但是英文实在太烂了，还是再改改吧。于是乎，2012年就过去了。
2013年 转眼来到了2013年。手头还是那个想法，还是那几篇半成品的论文，猩猩还是那个猩猩，月亮还是那个月亮。老板说这次要投CoNext。CoNext在六月截稿，所以过完年以后还有三个月的时间准备，时间看起来挺充分的，充分的我还在4月份实现了和这个完全无关的另一个算法。老板又是不闻不问，到了截稿前一周的时候，时间开始变紧。这次老板还叫了另一个教授L。老板说L很看好这个工作，然后L就消失了，到截稿前一天晚上才出现。
然后又是一场灾难，真是彻底的灾难。截稿前我简直可以说是纠缠着老板解释我的想法，希望他能理解然后帮我修改论文，结果没人屌。到截稿头天晚上，开始大吵，skype上都要打爆了，谁也说服不了谁，以至于L开始怀疑我这工作的是否真的有意义。那一夜，Oh那一夜，真是煎熬啊。他妈早干什么去了？截稿完了之后，真的很难过。本来抱了很大的信心，结果竟然是这么一个无言的结局。本来奋战一夜应该好好休息，结果我完全睡不着。到了下午一点的时候才发现，冰箱里已经没有什么存货了，想到欧洲周日商店都不开门，如果今天不去超市明天就得饿肚子，只好惨兮兮的去超市进货，买完东西回来以后都下午4点了，累的不行，结果发现教授L还语重心长的给我写了一份信，说什么Young researchers都有普遍的误区，以为发表了顶会就能成为牛逼的研究者，其实并不其然，应该是首先成为了牛逼的研究者才能发表顶级会议论文。我当时还虚心接受教训，回了封信装孙子说徒儿知错了，今后一定好好学习，天天向上。回完之后，感觉眼睛都熬干了，终于熟睡过去。其实这个时候，6月份了，应该到了该好好找工作的时候，但是当时心里想的更多的还是这个挫折，这个论文，题也没有好好刷，现在想来实在是得不偿失。投稿后的一周，我为了证明自己又做了一堆实验，还给L发了一个实验报告。不出所料，杳无音讯。
2014年 工作找完之后，已经到了年初。找了一圈互联网公司，就拿到了阿里和美团的offer，后来都没去，当然这些都不是描述的重点，当时找工作的时候确实也很大意，完全没有投入的去找。到了三月份又回到法国，待最后的三个月。2014年其实真心是很艰苦的一年，两个毕业论文，一个英文一个中文，没有毕业旅行，没有工作后的释然和重新出发的快感，战役没有结束，一切都要继续。三月初的时候，压力大到整夜整夜的失眠，后来决定每天跑步，在出汗中消除焦虑，制定严格的进度计划，每周工作六天半，留出周六上午去超市买菜。这里我很感谢当时和我在Annecy一起奋战的同学，群哥，义鹏还有李戈，没有你们的陪伴，我估计早崩溃了。最后目标一一都落实了。说实话我的毕业论文质量我自认为还真算比较高的，自认为对得起这三年的苦逼，尤其是对各个算法的全面总结，那个深度是够了的，广度是有了的。
回国之后继续做实验，准备把之前那个论文投到ICNP去。ICNP是IEEE的模板，本来就比ACM的模板字体要小，结果当年还尼玛特傻逼的说最长可以写12页。我是完全不惧，实验结果多的都快放不下，后来还忍痛删了几个。又是一夜没睡，在deadline前投出。我记得deadline是第二天中午，当时已经人已经熬不动了，投完稿就跟投了胎一样，过了奈何桥，回家倒头就睡。
在六月的时候，有一天周六，我正准备去查看一下单位给的福利廉租房，结果接到老板的电话。Irony, 一开始我以为他又要分什么活，结果就没接，后来又打了一个，我说尼玛看来不能躲了，就接了，结果是告诉我，恭喜，论文中了。据说，我的论文是没有上会讨论的，直接就中了，排名在中了的36篇论文中属于前18名。我记得那天是大晴天，北京天空很蓝，我来到上地，想到前几月我还在这里面了小米，如果小米给了offer，我很可能就不搞科研去公司了，忽然感慨良久。
##It&amp;rsquo;s (not) a happy ending
法国老板后来还跟我说，我那个论文投亏了，档次在ICNP之上。我的感触却是好歹投出去了，别再等了，万一一辈子烂在手里不更恶心。从提出想法到最后发表，都尼玛两年了。好多灌水的都尼玛四五篇论文在手了，哪有我这种像神经病一样执着的人。整个读博过程漫长而充满挫折，现在想起来很多时候，苦闷是一种常态，而释放和快感都太短暂。博士这六七年留下了什么，又收获了什么，一切都是似乎都是只是我执。执意为了证明自己，执意要发论文，然而这有什么用？
记得当时在做这个研究时候，我还有一个意外的发现。现在想来也挺有意思的，可能是唯一和科研有点关系的东西。我当时做了一个模型，能够预测某些算法的性能。结果发现我的模型总和实验结果误差很大，我的模型总说这个算法效果会很好，但是实际算法效果却很差。一开始我自然认为是我的模型错了，结果后来发现并不是，而是这个算法实现的有问题。我修正了他的实现，结果发现比他论文中的效果好了几十倍。我当时还觉得这不就是理论指导实践嘛，心里偷着乐，觉得感受到了科研的乐趣。后来我继续深究了这个问题，又发现这个问题应该是不存在的，之所以存在是因为人们对实验数据的使用是有问题的。有了这个发现之后，我突然觉得可笑，对实验数据的认识都是错的，人们还发了那么多论文号称自己的方法多么多么牛逼。太可笑了。
不过，这个研究让我明白了一个道理，大家都在扯淡，放松放松。
You are (not) alone 做研究真的是很孤独的一件事情。想想你的同龄人，都在努力工作拼命赚钱，而你搞的东西谁也不懂，有时候甚至你的老板、实验室的同事都不懂，跟赚钱更是毫无关系。搞出来除了发一篇paper也没有什么用。据说一篇paper的平均阅读量，全世界也不超过10个人，所以学术界基本就是一群神经病在一起写一些没人看的文章自high。早些年看The Ph.D. Grind，发现不是国内的教授sb导致国内的博士苦逼，而是天下乌鸦一般黑，哪里的博士都苦，哪怕你是Standford。作者最后也说自己实在受不了，离开了学术界去了Google上班。有意思的是，前几天看作者主页，发现他又回来做讲师了。人生，看来哪里都是围城。
可待成追忆 毕业之后，心态上调整了很多。当年的苦闷，消减了很多。这也跟整个人的关注点不再仅限于论文有关。人生就这么十几年，干什么都是在消耗，很多时候，没必要那么执着的证明什么。做研究还是需要fun一点。只是国内的这种氛围，你也懂的，基本上口味已经不属于fun而是属于joke的范畴了。Anyway，反正毕业了。一晃一年过去了。这些科研的故事也离我渐行渐远，当年的失落与兴奋，都慢慢陌生起来，在这里记录下来，纯当念想。</description>
    </item>
    
    
    
    <item>
      <title>找到一个地方写点东西</title>
      <link>https://xnhp0320.github.io/%E6%89%BE%E5%88%B0%E4%B8%80%E4%B8%AA%E5%9C%B0%E6%96%B9%E5%86%99%E7%82%B9%E4%B8%9C%E8%A5%BF/</link>
      <pubDate>Sat, 13 Jun 2015 17:02:18 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/%E6%89%BE%E5%88%B0%E4%B8%80%E4%B8%AA%E5%9C%B0%E6%96%B9%E5%86%99%E7%82%B9%E4%B8%9C%E8%A5%BF/</guid>
      <description>这是第一篇文章，算是测试，也算是占坑。 对Markdown的语法也不算太熟，不过我也不打算把这里搞成太技术。 似乎就对Markdown的语法无需太多了解？
Anyway, 终于可以不需要在校内上写文章，话说现在谁还在校内上瞎逼逼啊。 写出来也没人看不是。。。
花了一个小时搭了一个博客，又花了一个小时给博客加上了评论栏，再往下就是 加图床了。忽然发现自己真的out了。现在云里的东西真的很多，存储，评论， 而且真的很方便，文科生也能弄（我不是鄙视文科生。。。）
以后就在这里发发牢骚。今天就到此吧，想想还是有点小成就感。</description>
    </item>
    
    
    
    <item>
      <title></title>
      <link>https://xnhp0320.github.io/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://xnhp0320.github.io/</guid>
      <description>网络虚拟化的一种本质 做虚拟网络也有几年了，最近产生了一些想法，就想着记下来。
我记得在读书的时候，搞过一阵子未来网络的体系结构。当时看了一些资料，记得有一个RFC曾经指出了IPv4网络设计的一个局限性，就是把identify（标识）和 location（寻址）的绑定在同一个IP地址上。这个论断，当时看还是很震惊的，感觉非常精辟。怎么理解这个论断呢，其实标识就是名字，说白了就是你是谁，寻址的话也很好理解，就是你在哪。在网络世界里，如果两个IP地址很接近，比如前缀相等，那么你可以认为他可能就在同一个交换机下，这其实就是一种对位置的界定。
在静态网络中，这种绑定其实没有什么问题。但是一旦网络中的个体开始移动，问题就来了，比如一个客户端，具有某个IP1的client移动到了另一个位置，那么按照方便寻址的原则，他在另一个地方的地址应该是另一个地址IP2。但是如果client正处于一个TCP连接中，换掉地址，就相当于五元组变了，那么连接就被破坏，相当于断网。为了一个新的地址，直接丢弃了所有老连接，这就很麻烦。为了解决这些，我记得移动网络中有一个所谓的“三角路由”的概念。具体是啥也忘记了。但是这个寻址和标识的绑定是IPv4网络的局限性的论断，这么多年我都记得。为了解除这个问题，Cisco曾经提出了一个叫LISP，Location Identification Separate Protocol，就是把IP地址分为两类，一类作为标识，一类作为地址，网络中的设备都有两个地址，直接解除了IPv4的这一局限性。可惜当前的互联网已经不可能重来了。
那么这个标识和寻址的绑定和网络虚拟化有啥关系呢？其实之前我在做的时候，也没想过有啥关系。网络虚拟化本质就是overlay技术，说白了就是一个underlay多个overlay。打个隧道连通下各个主机，隧道的目的是为了防止地址overlap，overlay网络中要尽可能的模拟现有的网络，比如二层泛洪，三层路由等等。直到我见到了纯三层虚拟网络，我突然想明白了点什么。
纯三层的虚拟网络里，每个虚机都是/32的掩码，也就是每个虚机自身就是一个子网。任何两个虚机之间的互访就是三层路由。这固然有些限制，比如二层设备里一些基于arp欺骗的主备网络设备的玩法搞不了了，但是对于大多数业务来说，基本没影响。而且，这个限制对虚拟网络的设计来说其实省了一大堆的事情，比如arp在虚拟网络中的泛洪，虚机迁移之后的免费arp发布刷cache等等。
当然这个设计中最重要的一点还是让我立刻理解了虚拟网络中地址已经和位置无关了。试想，两个虚机的IP地址前缀相同，能说明他就一定靠的很近吗？不，有可能这两个虚机在两个相隔甚远的物理机上。既然前缀已经不能决定位置了，干脆就放弃前缀，放弃了前缀就是放弃了虚拟子网，放弃了广播域，放弃了冲突域。虚机的标识就是IP地址，而这个IP地址与虚机的位置毫无关系。所以纯三层虚拟网络，就是暴露了虚拟网络的另一种本质。如果你看着一个vxlan数据包，他的外层IP地址负责寻址，而内层IP地址就是标识。Cisco想实现的LISP，在虚拟网络中实现了。历史总是惊人的相似！
因而虚机的路由表在vswitch中是不能收敛的。每个虚机都会贡献一个路由表项到虚机，没有前缀路由，只有明细路由。因为去往每个虚机的下一跳都可能是不同的宿主机。一个有10w虚机的网络，路由表就有10w条。
这和今天的互联网的骨干网何其类似。因为绑定了标识信息，骨干网络的route表项年年上升，我博士在读时候是350K条，现在貌似远超500K条了。看样子，IP查找算法的研究还可以再续命三年。
那么除了这套玩法，我们还有别的玩法么？当然有，当我们不在意IP地址，而用URL来实现服务标识，玩法又变化了。这块下次再说吧，敲字有点累了。</description>
    </item>
    
    
  </channel>
</rss>
